---
version: 2.1

# Command definitions
commands:
  destroy-environment:
    description: Destroy cluster and any deployed workloads
    parameters:
      run_when:
        type: string
        default: on_fail
      deployment_target:
        type: string
    steps:
      - run:
          name: Install kubectl
          when: << parameters.run_when >>
          command: |
            curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
            sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
      - run:
          name: Install eksctl
          when: << parameters.run_when >>
          command: |
            curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/v0.114.0/eksctl_Linux_amd64.tar.gz" \
            | tar xz -C /tmp
            sudo mv /tmp/eksctl /usr/local/bin
      - run:
          name: Update kubectl config for target cluster
          when: << parameters.run_when >>
          command: |
            if [ << parameters.deployment_target >> == "old" ]
              then
                TARGET_CLUSTER=$(curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/previousclustername")
                
                if [ -n "${TARGET_CLUSTER}" ]
                  then
                    echo "Destroy previous deployment: ${TARGET_CLUSTER}"
                    aws eks --region us-east-1 update-kubeconfig --name ${TARGET_CLUSTER}
                  else
                    echo "No old deployment to clean up"
                    exit 0
                fi
            elif [ << parameters.deployment_target >> == "current" ]
              then
                TARGET_CLUSTER="capstone-cluster-${CIRCLE_WORKFLOW_ID:0:7}"
                echo "Destroy current deployment: ${TARGET_CLUSTER}"
                aws eks --region us-east-1 update-kubeconfig --name ${TARGET_CLUSTER}
            fi
      - run:
          name: Delete namespace (should destroy all child objects)
          when: << parameters.run_when >>
          command: |
            if kubectl get ns udacity-capstone
              then
                echo "Deleting namespace on: $(kubectl config current-context)"
                kubectl delete ns udacity-capstone
              else
                echo "Namespace not found on: $(kubectl config current-context)"
            fi
      - run:
          name: Delete EKS cluster
          no_output_timeout: 30m
          when: << parameters.run_when >>
          command: |
            if [ << parameters.deployment_target >> == "old" ]
              then
                TARGET_CLUSTER=$(curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/previousclustername")
              else
                TARGET_CLUSTER="capstone-cluster-${CIRCLE_WORKFLOW_ID:0:7}"
            fi

            echo ${TARGET_CLUSTER}

            eksctl delete cluster --name ${TARGET_CLUSTER}
    
# Job definitions
jobs:
  lint-code:
    docker:
      - image: python:3.7.3-stretch
    steps:
      - checkout
      - run:
          name: Setup lint environment
          command: |
            ls
            make setup
      - run:
          name: Run lint checks
          command: |
            make lint
  
  build-docker-image:
    docker:
      - image: cimg/aws:2022.09.1 #cimg/base:2022.10
        #user: root
    steps:
      - checkout
      - setup_remote_docker:
          version: 20.10.18

      # Build image and list built image    
      - run: |
          docker build -t cap-test .
          docker image ls | grep cap-test
          #sudo docker build -t cap-test . 
          #sudo docker image ls | grep cap-test

      # run the container detatched and list running containers
      - run: |
          docker run -d --name cap-app-test -p 8000:80 cap-test
          docker ps
          #sudo docker run -d --name cap-app-test -p 8000:80 cap-test
          #sudo docker ps

      # Check the container is running OK and returns a 200 response    
      - run: |
          SERVICE_STATUS=$(docker exec cap-app-test \
                          curl -I -s -o /dev/null -w "%{http_code}" \
                          --retry 4 --retry-connrefused http://localhost:80)
          
          if [ "${SERVICE_STATUS}" == '200' ]
            then
              echo "Success code 200 received"
          else
            echo "Service test failed"
            exit 1
          fi

      # push the image to ECR registry
      - run: | 
          aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 990469894386.dkr.ecr.us-east-1.amazonaws.com
          docker tag cap-test:latest 990469894386.dkr.ecr.us-east-1.amazonaws.com/cap-test:latest
          docker push 990469894386.dkr.ecr.us-east-1.amazonaws.com/cap-test:latest

  create-and-deploy:
    docker:
      - image: cimg/aws:2022.09.1
    steps:
      - checkout
      - run:
          name: Install Ansible
          command: |
            sudo apt-get update
            echo "installing Ansible"
            sudo apt-get install ansible -y
      - run:
          name: Record name of existing cluster
          command: |
            echo "ID: $AWS_ACCESS_KEY_ID"
            echo "secret: $AWS_SECRET_ACCESS_KEY"
            echo "reg: $AWS_DEFAULT_REGION"

            EXISTING_CLUSTER=$(aws eks list-clusters | jq -r '.clusters[]|select(. | startswith("capstone-cluster-"))')
            echo "Existing cluster name: ${EXISTING_CLUSTER}"
            curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/previousclustername" -d "${EXISTING_CLUSTER}"
      - run:
          name: Create EKS cluster using eksctl tool
          no_output_timeout: 30m
          command: |
            cd ansible/
            ansible-playbook create-eks-cluster.yml
      # Perform kubectl commands
      - run:
          name: List cluster nodes
          command: |
            kubectl get nodes
      # Deploy application to EKS cluster      
      - run:
          name: Deploy k8s manifests to cluster
          command: |
            NS_WAIT=3

            kubectl apply -f k8s_manifests/namespace.yml

            while [ $(kubectl get ns udacity-capstone -o jsonpath='{.status.phase}') != "Active" ] && [ $attempts -lt 2 ]
            do 
                attempts=$((attempts+1))
                echo "waiting for application namespace to be ready"
                sleep 5
            done

            kubectl apply -f k8s_manifests/
            kubectl -n udacity-capstone rollout status deployment capstone-project

      - run:
          name: Record name of load balancer endpoint
          command: |
            sleep 5 
            SVC_WAIT=2
            # while [[ -z $(kubectl -n udacity-capstone get svc -o json | jq -r '.items[] | select(.metadata.name | startswith( "capstone-nginx-"))') ]]
            #   do
            #     echo "waiting for k8s service to be available.."
            #     sleep 2
            SVC_ENDPOINT=$(kubectl -n udacity-capstone get svc -o json \
                          | jq -r '.items[] | select(.metadata.name | startswith( "capstone-nginx-")) | .status.loadBalancer.ingress[].hostname')
            echo "Service Endpoint: ${SVC_ENDPOINT}"
            curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/serviceendpoint" -d "${SVC_ENDPOINT}"
      
      - destroy-environment:
          run_when: on_fail
          deployment_target: current
   
  smoke-tests:
    docker:
      - image: cimg/aws:2022.09.1 #python:3.7.3-stretch
    steps:
      - run:
          name: Install prereqs
          command: |
            sudo apt-get update
            sudo apt-get install curl -y
      - run:
          name: Check connectivity to application
          command: |
            SVC_ENDPOINT="$(curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/serviceendpoint")"
            ATTEMPTS=0
            PASSED=false

            while  [ ! ${PASSED} = true ] && [ $ATTEMPTS -lt 2 ]
            do 
              ATTEMPTS=$((ATTEMPTS+1))
              echo "waiting for load balancer service to come up"
              echo "TARGET: ${SVC_ENDPOINT}:8000"
              if curl -s http://${SVC_ENDPOINT}:8000 | grep 'Stephen Bold'
                then
                  PASSED=true
              fi
              sleep 15
            done

            if ${PASSED} = true
              then
                echo "Application check passed"
              else
                echo "Application check failed to test successfully over 120 seconds"
                exit 1
            fi
      - destroy-environment:
          run_when: on_fail
          deployment_target: current
    
  cleanup-old-deployment:
    docker:
      - image: cimg/aws:2022.09.1
    steps:
      # - run:
      #     name: Install kubectl
      #     command: |
      #       curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
      #       sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
      # - run:
      #     name: Install eksctl
      #     command: |
      #       curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/v0.114.0/eksctl_Linux_amd64.tar.gz" \
      #       | tar xz -C /tmp
      #       sudo mv /tmp/eksctl /usr/local/bin
      # - run:
      #     name: Fetch old cluster name
      #     command: |
      #       export OLD_CLUSTER=$(curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/previousclustername")
      #       echo ${OLD_CLUSTER}
      - destroy-environment:
          run_when: on_success
          deployment_target: old
   
# Workflow definitions
workflows:
  deploy:
    jobs:
      - lint-code
      - build-docker-image:
          requires:
            - lint-code
      - create-and-deploy:
          requires:
            - build-docker-image
          filters:
            branches:
              only:
                - main
      - smoke-tests:
          requires:
            - create-and-deploy
      - cleanup-old-deployment:
          requires:
            - smoke-tests