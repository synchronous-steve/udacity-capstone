---
version: 2.1

# Command definitions
commands:
  destroy-environment:
    description: Destroy cluster and any deployed workloads
    parameters:
      run_when:
        type: string
        default: on_fail
      cluster_name:
        type: string
    steps:
      - run:
          name: Update kubectl config for target cluster
          command: |
            echo << parameters.cluster_name >>
            aws eks --region us-east-1 update-kubeconfig --name << parameters.cluster_name >>
      - run:
          name: Delete namespace (should destroy all child objects)
          when: << parameters.run_when >>
          command: |
            echo "Deleting namespace on: $(kubectl config current-context)""
            kubectl delete ns udacity-capstone
      - run:
          name: Delete EKS cluster
          when: << parameters.run_when >>
          command: |
            eksctl delete cluster --name << parameters.cluster_name >>
    
# Job definitions
jobs:
  lint-code:
    docker:
      - image: python:3.7.3-stretch
    steps:
      - checkout
      - run:
          name: Setup lint environment
          command: |
            ls
            make setup
      - run:
          name: Run lint checks
          command: |
            make lint
  
  build-docker-image:
    docker:
      - image: cimg/aws:2022.09.1 #cimg/base:2022.10
        #user: root
    steps:
      - checkout
      - setup_remote_docker:
          version: 20.10.18

      # Build image and list built image    
      - run: |
          sudo docker build -t cap-test .
          sudo docker image ls | grep cap-test

      # run the container detatched and list running containers
      - run: |
          sudo docker run -d --name cap-app-test -p 8000:80 cap-test
          sudo docker ps

      # Check the container is running OK and returns a 200 response    
      - run: |
          SERVICE_STATUS=$(sudo docker exec cap-app-test \
                          curl -I -s -o /dev/null -w "%{http_code}" \
                          --retry 4 --retry-connrefused http://localhost:80)
          
          if [ "${SERVICE_STATUS}" == '200' ]
            then
              echo "Success code 200 received"
          else
            echo "Service test failed"
            exit 1
          fi

      # push the image to ECR registry
      - run: | 
          aws ecr get-login-password --region us-east-1 | sudo docker login --username AWS --password-stdin 990469894386.dkr.ecr.us-east-1.amazonaws.com #053645246680.dkr.ecr.us-east-1.amazonaws.com
          sudo docker tag cap-test:latest 990469894386.dkr.ecr.us-east-1.amazonaws.com/cap-test:latest #053645246680.dkr.ecr.us-east-1.amazonaws.com/cap-test:latest
          sudo docker push 990469894386.dkr.ecr.us-east-1.amazonaws.com/cap-test #053645246680.dkr.ecr.us-east-1.amazonaws.com/cap-test:latest

  create-and-deploy:
    docker:
      - image: cimg/aws:2022.09.1
    steps:
      - checkout
      - run:
          name: Install Ansible
          command: |
            sudo apt-get update
            echo "installing Ansible"
            sudo apt-get install ansible -y
      - run:
          name: Record name of existing cluster
          command: |
            echo "ID: $AWS_ACCESS_KEY_ID"
            echo "secret: $AWS_SECRET_ACCESS_KEY"
            echo "reg: $AWS_DEFAULT_REGION"

            EXISTING_CLUSTER=$(aws eks list-clusters | jq -r '.clusters[]|select(. | startswith("capstone-cluster-"))')
            echo "Existing cluster name: ${EXISTING_CLUSTER}"
            curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/previousclustername" -d "${EXISTING_CLUSTER}"
      - run:
          name: Create EKS cluster using eksctl tool
          no_output_timeout: 25m
          command: |
            cd ansible/
            ansible-playbook create-eks-cluster.yml
      # Perform kubectl commands
      - run:
          name: List cluster nodes
          command: |
            #aws eks --region us-east-1 update-kubeconfig --name capstone-cluster-${CIRCLE_WORKFLOW_ID}
            kubectl get nodes
      # Deploy application to EKS cluster      
      - run:
          name: Deploy k8s manifests to cluster
          command: |
            NS_WAIT=3

            kubectl apply -f k8s_manifests/namespace.yml

            while [ $(kubectl get ns udacity-capstone -o jsonpath='{.status.phase}') != "Active" ] && [ $attempts -lt 2 ]
            do 
                attempts=$((attempts+1))
                echo "waiting for application namespace to be ready"
                sleep 5
            done

            kubectl apply -f k8s_manifests/
            kubectl -n udacity-capstone rollout status deployment capstone-project

      - run:
          name: Record name of load balancer endpoint
          command: |
            SVC_ENDPOINT=$(kubectl -n udacity-capstone get svc -o json \
                          | jq -r '.items[] | select(.metadata.name | startswith( "capstone-nginx-")) | .status.loadBalancer.ingress[].hostname')
            echo "Existing cluster name: ${SVC_ENDPOINT}"
            curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/serviceendpoint" -d "${SVC_ENDPOINT}"
      
      - destroy-environment:
          run_when: on_fail
          cluster_name: capstone-cluster-${CIRCLE_WORKFLOW_ID:0:7}
   
  smoke-tests:
    docker:
      - image: python:3.7.3-stretch
    steps:
      - run:
          name: Install prereqs
          command: |
            apt-get update
            apt-get install curl -y
      - run:
          name: Check connectivity to application
          command: |
            SVC_ENDPOINT="$(curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/serviceendpoint")"
            ATTEMPTS=0
            PASSED=false

            while  [ ! ${PASSED} = true ] && [ $ATTEMPTS -lt 7 ]
            do 
              ATTEMPTS=$((ATTEMPTS+1))
              echo "waiting for load balancer service to come up"
              if curl -s http://${SVC_ENDPOINT}:8000 | grep 'Stephen Bold'
                then
                  PASSED=true
              fi
              sleep 15
            done

            if ${PASSED} = true
              then
                echo "Application check passed"
              else
                echo "Application check failed to test successfully over 105 seconds"
                exit 1
            fi
  
  cleanup-old-deployment:
    docker:
      - image: cimg/aws:2022.09.1
    steps:
      - run:
          name: Install kubectl
          command: |
            curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
            sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
      - run:
          name: Fetch old cluster name
          command: |
            OLD_CLUSTER=$(curl -k "https://kvdb.io/W731k82q3QKRA74QoPjp86/previousclustername")
            echo ${OLD_CLUSTER}
      - destroy-environment:
          run_when: on_success
          cluster_name: "${OLD_CLUSTER}"

       
# Workflow definitions
workflows:
  deploy:
    jobs:
      - lint-code
      - build-docker-image:
          requires:
            - lint-code
      - create-and-deploy:
          requires:
            - build-docker-image
      - smoke-tests:
          requires:
            - create-and-deploy
      - cleanup-old-deployment:
          requires:
            - smoke-tests